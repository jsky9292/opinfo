#!/usr/bin/env python3
"""
ì´ë¯¸ í¬ë¡¤ë§ëœ ë°ì´í„°ì— ì›ë³¸ descriptionì—ì„œ districtë¥¼ ì¶”ì¶œí•˜ì—¬ ì¶”ê°€
"""
import json
import re

# 1. ì›ë³¸ ì…ë ¥ íŒŒì¼ ì½ê¸° (description ìˆìŒ)
with open('daejeon_chungcheong_all_20251009_220324.json', 'r', encoding='utf-8') as f:
    original_data = json.load(f)

# 2. í¬ë¡¤ë§ ì™„ë£Œ íŒŒì¼ ì½ê¸° (ì´ë¯¸ì§€ ìˆìŒ)
with open('details_fixed_complete_20251013_231951.json', 'r', encoding='utf-8') as f:
    crawled_data = json.load(f)

print(f'ì›ë³¸ ë°ì´í„°: {len(original_data)}ê°œ')
print(f'í¬ë¡¤ë§ ë°ì´í„°: {len(crawled_data)}ê°œ')

# 3. URLì„ keyë¡œ í•˜ëŠ” dict ìƒì„±
original_dict = {item['url']: item for item in original_data}

# 4. í¬ë¡¤ë§ ë°ì´í„°ì— ì„¸ë¶€ ì§€ì—­ ì¶”ê°€
fixed_count = 0
for shop in crawled_data:
    url = shop['url']

    # ì›ë³¸ ë°ì´í„°ì—ì„œ description ì°¾ê¸°
    if url in original_dict:
        original_desc = original_dict[url].get('description', '')

        # descriptionì—ì„œ "ë™" ì¶”ì¶œ
        if original_desc:
            district_match = re.search(r'([ê°€-í£]+ë™)', original_desc)
            if district_match:
                extracted_district = district_match.group(1)
                shop['district'] = extracted_district
                fixed_count += 1

print(f'\nâœ… ì„¸ë¶€ ì§€ì—­ ì¶”ì¶œ ì„±ê³µ: {fixed_count}ê°œ ({fixed_count/len(crawled_data)*100:.1f}%)')

# 5. ì €ì¥
output_file = 'details_fixed_with_districts.json'
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(crawled_data, f, ensure_ascii=False, indent=2)

print(f'ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}')

# 6. ìƒ˜í”Œ ì¶œë ¥
print('\nğŸ“ ìƒ˜í”Œ (ì„¸ë¶€ ì§€ì—­ ì¶”ì¶œë¨):')
samples = [x for x in crawled_data if x['district'] != x['area']][:10]
for s in samples:
    print(f'  {s["title"]:30s} â†’ {s["area"]:8s} / {s["district"]}')
