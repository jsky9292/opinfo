#!/usr/bin/env python3
"""
ëŒ€ì „ í¬ë¡¤ëŸ¬ ë°©ì‹ì„ ì ìš©í•œ ì „êµ­ ìƒì„¸ ì •ë³´ í¬ë¡¤ëŸ¬
- ëŒ€ì „ í¬ë¡¤ëŸ¬ì™€ ë™ì¼í•œ ì´ë¯¸ì§€ ìˆ˜ì§‘ ë¡œì§ ì‚¬ìš©
- íŒì—…/iframe ë‚´ë¶€ê¹Œì§€ íƒìƒ‰í•˜ì—¬ ëª¨ë“  ìƒì„¸ ì´ë¯¸ì§€ ìˆ˜ì§‘
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time, json, re
from datetime import datetime

USERNAME = 'mix1220'
PASSWORD = '1234'

class DetailCrawler:
    def __init__(self):
        self.driver = None
        self.results = []

    def setup(self):
        print('ë¸Œë¼ìš°ì € ì„¤ì •...')
        opts = Options()
        opts.add_argument('--no-sandbox')
        opts.add_argument('--disable-dev-shm-usage')
        opts.add_argument('--disable-blink-features=AutomationControlled')
        opts.add_argument('--headless')  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
        opts.add_argument('--window-size=1920,1080')
        opts.add_experimental_option("excludeSwitches", ["enable-automation"])
        opts.add_experimental_option('useAutomationExtension', False)
        opts.add_argument(
            'user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
            'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        )

        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)
        self.driver.set_page_load_timeout(30)

        # ìë™í™” ê°ì§€ ë°©ì§€
        self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {
            "userAgent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        self.driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )

        print('ì¤€ë¹„ ì™„ë£Œ')

    def login(self):
        print('ë¡œê·¸ì¸...')
        self.driver.get('https://dkxm8.com/bbs/login.php')
        time.sleep(2)
        self.driver.find_element(By.NAME, 'mb_id').send_keys(USERNAME)
        self.driver.find_element(By.NAME, 'mb_password').send_keys(PASSWORD)
        self.driver.find_element(By.CSS_SELECTOR, 'input[type=submit]').click()
        time.sleep(3)
        print('ë¡œê·¸ì¸ ì™„ë£Œ')

    def get_profile_details(self, profile_url):
        """í”„ë¡œí•„ íŒì—…ì—ì„œ ìƒì„¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸° (ëŒ€ì „ í¬ë¡¤ëŸ¬ ë°©ì‹)"""
        detail_images = []
        original_window = self.driver.current_window_handle

        try:
            # ìƒˆ ì°½ì—ì„œ í”„ë¡œí•„ ì—´ê¸°
            self.driver.execute_script(f"window.open('{profile_url}', '_blank');")
            time.sleep(2)

            # ìƒˆ ì°½ìœ¼ë¡œ ì „í™˜
            windows = self.driver.window_handles
            self.driver.switch_to.window(windows[-1])
            time.sleep(2)

            # iframeì´ ìˆë‹¤ë©´ ì „í™˜
            try:
                iframes = self.driver.find_elements(By.TAG_NAME, "iframe")
                if iframes:
                    self.driver.switch_to.frame(iframes[0])
                    time.sleep(1)
            except:
                pass

            # ëª¨ë“  ì´ë¯¸ì§€ ìˆ˜ì§‘
            try:
                imgs = self.driver.find_elements(By.TAG_NAME, "img")
                for img in imgs:
                    try:
                        src = img.get_attribute('src')
                        # /data/file/ ë˜ëŠ” /data/editor/ ê²½ë¡œ ì´ë¯¸ì§€ë§Œ
                        if src and ('/data/file/' in src or '/data/editor/' in src):
                            if not src.startswith('http'):
                                src = 'https://dkxm8.com' + src
                            if src not in detail_images:
                                detail_images.append(src)
                    except:
                        continue
            except:
                pass

            # iframeì—ì„œ ë¹ ì ¸ë‚˜ì˜¤ê¸°
            try:
                self.driver.switch_to.default_content()
            except:
                pass

            # íŒì—… ë‹«ê³  ì›ë˜ ì°½ìœ¼ë¡œ ëŒì•„ê°€ê¸°
            self.driver.close()
            self.driver.switch_to.window(original_window)
            time.sleep(0.5)

        except Exception as e:
            print(f'   âš ï¸  íŒì—… ì²˜ë¦¬ ì˜¤ë¥˜: {e}')
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë³µêµ¬
            try:
                self.driver.switch_to.default_content()
            except:
                pass
            try:
                windows = self.driver.window_handles
                if len(windows) > 1:
                    self.driver.close()
                if windows:
                    self.driver.switch_to.window(original_window)
            except:
                pass

        return detail_images

    def get_shop_detail(self, url, title, area, original_description=''):
        """ê° ì—…ì†Œì˜ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        try:
            self.driver.get(url)
            time.sleep(1.5)

            detail = {
                'title': title,
                'url': url,
                'area': area,
                'district': area,  # ì„¸ë¶€ ì§€ì—­ (ë™ ì´ë¦„), ê¸°ë³¸ê°’ì€ í° ì§€ì—­
                'thumbnail': '',
                'detail_images': [],  # ìƒì„¸ ì´ë¯¸ì§€ë“¤
                'description': '',
                'phone': '',
                'hours': '',
                'kakao_id': '',
                'telegram_id': ''
            }

            # ì›ë³¸ descriptionì—ì„œ ì„¸ë¶€ ì§€ì—­ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„)
            if original_description:
                district_match = re.search(r'([ê°€-í£]+ë™)', original_description)
                if district_match:
                    detail['district'] = district_match.group(1)

            # ğŸ”¥ ëŒ€ì „ í¬ë¡¤ëŸ¬ ë°©ì‹ìœ¼ë¡œ ìƒì„¸ ì´ë¯¸ì§€ ìˆ˜ì§‘
            detail_images = self.get_profile_details(url)

            if detail_images:
                detail['thumbnail'] = detail_images[0]
                detail['detail_images'] = detail_images
            else:
                # fallback: ê¸°ì¡´ ë°©ì‹
                try:
                    img_elements = self.driver.find_elements(By.CSS_SELECTOR, '.imgWrap img[src*="data/editor"]')
                    image_urls = []

                    for img in img_elements:
                        src = img.get_attribute('src')
                        if src and src not in image_urls:
                            image_urls.append(src)

                    if image_urls:
                        detail['thumbnail'] = image_urls[0]
                        detail['detail_images'] = image_urls
                    else:
                        detail['thumbnail'] = 'https://dkxm8.com/img/temp_thum.jpg'
                except:
                    detail['thumbnail'] = 'https://dkxm8.com/img/temp_thum.jpg'

            # í˜ì´ì§€ ì „ì²´ HTML ê°€ì ¸ì˜¤ê¸°
            page_text = self.driver.find_element(By.TAG_NAME, 'body').text

            # ì„¤ëª…/ì†Œê°œê¸€ ì¶”ì¶œ ë° ì„¸ë¶€ ì§€ì—­ ì¶”ì¶œ
            try:
                lines = page_text.split('\n')
                district = None

                for line in lines:
                    line = line.strip()

                    # ì„¸ë¶€ ì§€ì—­ ì¶”ì¶œ (ë™ ì´ë¦„ì´ ìˆëŠ” ê²½ìš°)
                    if 'ë™' in line and not district:
                        district_match = re.search(r'([ê°€-í£]+ë™)', line)
                        if district_match:
                            district = district_match.group(1)

                    # 15~80ì ì‚¬ì´ì˜ í™ë³´ì„± ë¬¸êµ¬
                    if 15 <= len(line) <= 80:
                        if any(k in line for k in ['â¤', 'âœ¨', 'â­', 'âœ…', 'â™¥', 'ì‹ ê·œ', 'ì´ë²¤íŠ¸', 'í• ì¸', 'NF', 'í•œêµ­', 'ì‹¤ì‚¬']):
                            detail['description'] = line

                # ì„¸ë¶€ ì§€ì—­ì´ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                if district:
                    detail['district'] = district
            except:
                pass

            # ì˜ì—…ì‹œê°„ ì¶”ì¶œ
            try:
                for line in lines:
                    line = line.strip()
                    if re.search(r'(AM|PM|\d{1,2}:\d{2}|\d{1,2}ì‹œ)', line, re.IGNORECASE):
                        if 10 <= len(line) <= 60:
                            detail['hours'] = line
                            break
            except:
                pass

            # ì „í™”ë²ˆí˜¸ ì¶”ì¶œ
            try:
                phone_pattern = r'(010[-\s]?\d{4}[-\s]?\d{4})'
                phones = re.findall(phone_pattern, page_text)
                if phones:
                    detail['phone'] = phones[0]
            except:
                pass

            # ì¹´ì¹´ì˜¤í†¡/í…”ë ˆê·¸ë¨ ë§í¬
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href]')
                for link in links:
                    href = link.get_attribute('href')
                    if 'kakao' in href.lower():
                        detail['kakao_id'] = href
                    elif 't.me' in href or 'telegram' in href.lower():
                        detail['telegram_id'] = href
            except:
                pass

            return detail

        except Exception as e:
            print(f'â†’ ì˜¤ë¥˜: {e}')
            return None

    def run(self, input_file, start_idx=0):
        print('='*60)
        print(f'ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ ì‹œì‘: {input_file}')
        print(f'ì‹œì‘ ì¸ë±ìŠ¤: {start_idx}')
        print('ëŒ€ì „ í¬ë¡¤ëŸ¬ ë°©ì‹ ì ìš© - íŒì—…/iframe íƒìƒ‰')
        print('='*60)

        # ì…ë ¥ íŒŒì¼ ì½ê¸°
        with open(input_file, 'r', encoding='utf-8') as f:
            shops = json.load(f)

        total = len(shops)
        shops_to_crawl = shops[start_idx:]

        print(f'\nì´ {len(shops_to_crawl)}ê°œ ì—…ì†Œ í¬ë¡¤ë§ ì‹œì‘ ({start_idx+1}~{total})...\n')

        self.setup()
        self.login()

        for idx, shop in enumerate(shops_to_crawl, start_idx+1):
            print(f'[{idx}/{total}] {shop["title"]} ({shop["area"]})', end=' ')

            original_desc = shop.get('description', '')

            detail = self.get_shop_detail(
                shop['url'],
                shop['title'],
                shop['area'],
                original_desc
            )

            if detail:
                self.results.append(detail)
                img_count = len(detail.get('detail_images', []))
                has_thumb = 'âœ“' if detail['thumbnail'] != 'https://dkxm8.com/img/temp_thum.jpg' else 'â—‹'
                print(f'{has_thumb} ({img_count}ì¥)')
            else:
                print('âœ—')

            # 10ê°œë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
            if idx % 10 == 0:
                temp_file = f'details_daejeon_style_temp_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(self.results, f, ensure_ascii=False, indent=2)
                print(f'  â†’ ì¤‘ê°„ ì €ì¥: {temp_file} ({len(self.results)}ê°œ)')

            time.sleep(1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

        # ìµœì¢… ì €ì¥
        output = f'details_daejeon_style_complete_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(output, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        # í†µê³„
        total_images = sum(len(r.get('detail_images', [])) for r in self.results)
        avg_images = total_images / len(self.results) if self.results else 0

        print(f'\nâœ… ì™„ë£Œ: {len(self.results)}ê°œ â†’ {output}')
        print(f'ğŸ“Š í†µê³„:')
        print(f'   - ì´ ì´ë¯¸ì§€ ìˆ˜: {total_images}ì¥')
        print(f'   - í‰ê·  ì´ë¯¸ì§€ ìˆ˜: {avg_images:.1f}ì¥/ì—…ì†Œ')

        self.driver.quit()

if __name__ == '__main__':
    crawler = DetailCrawler()
    # ì „êµ­ 461ê°œ ì—…ì†Œ í¬ë¡¤ë§ (ì²˜ìŒë¶€í„°)
    crawler.run('daejeon_chungcheong_all_20251009_220324.json', start_idx=0)
