#!/usr/bin/env python3
"""
ëª¨ë“  ì§€ì—­ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœíšŒí•˜ë©´ì„œ ì—…ì†Œ í¬ë¡¤ë§
"""
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time, json
from datetime import datetime

USERNAME = 'mix1220'
PASSWORD = '1234'

class AllAreasCrawler:
    def __init__(self):
        self.driver = None
        self.results = []
        # ì „êµ­ ëª¨ë“  ì§€ì—­ ëª©ë¡ (ì‚¬ì´íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì§€ì—­ëª…)
        self.areas = [
            # ì„œìš¸
            'ê°•ë‚¨', 'ê°•ë™', 'ê°•ë¶', 'ê°•ì„œ', 'ê´€ì•…', 'ê´‘ì§„', 'êµ¬ë¡œ', 'ê¸ˆì²œ',
            'ë…¸ì›', 'ë„ë´‰', 'ë™ëŒ€ë¬¸', 'ë™ì‘', 'ë§ˆí¬', 'ì„œëŒ€ë¬¸', 'ì„œì´ˆ', 'ì„±ë™',
            'ì„±ë¶', 'ì†¡íŒŒ', 'ì–‘ì²œ', 'ì˜ë“±í¬', 'ìš©ì‚°', 'ì€í‰', 'ì¢…ë¡œ', 'ì¤‘êµ¬',
            'ì¤‘ë‘',
            # ê²½ê¸°
            'ê³ ì–‘', 'ê³¼ì²œ', 'ê´‘ëª…', 'ê´‘ì£¼', 'êµ¬ë¦¬', 'êµ°í¬', 'ê¹€í¬', 'ë‚¨ì–‘ì£¼',
            'ë™ë‘ì²œ', 'ë¶€ì²œ', 'ì„±ë‚¨', 'ìˆ˜ì›', 'ì‹œí¥', 'ì•ˆì‚°', 'ì•ˆì„±', 'ì•ˆì–‘',
            'ì–‘ì£¼', 'ì—¬ì£¼', 'ì˜¤ì‚°', 'ìš©ì¸', 'ì˜ì™•', 'ì˜ì •ë¶€', 'ì´ì²œ', 'íŒŒì£¼',
            'í‰íƒ', 'í¬ì²œ', 'í•˜ë‚¨', 'í™”ì„±',
            # ì¸ì²œ
            'ì¸ì²œ',
            # ê°•ì›
            'ê°•ë¦‰', 'ë™í•´', 'ì‚¼ì²™', 'ì†ì´ˆ', 'ì›ì£¼', 'ì¶˜ì²œ', 'íƒœë°±', 'í™ì²œ',
            # ì¶©ë¶
            'ì œì²œ', 'ì²­ì£¼', 'ì¶©ì£¼', 'ì§„ì²œ', 'ìŒì„±', 'ì˜¤ì°½',
            # ì¶©ë‚¨
            'ê³„ë£¡', 'ê³µì£¼', 'ë…¼ì‚°', 'ë‹¹ì§„', 'ë³´ë ¹', 'ì„œì‚°', 'ì•„ì‚°', 'ì²œì•ˆ',
            'í™ì„±',
            # ëŒ€ì „/ì„¸ì¢…
            'ëŒ€ì „', 'ì„¸ì¢…',
            # ì „ë¶
            'êµ°ì‚°', 'ê¹€ì œ', 'ë‚¨ì›', 'ìµì‚°', 'ì „ì£¼', 'ì •ì',
            # ì „ë‚¨
            'ê´‘ì–‘', 'ë‚˜ì£¼', 'ëª©í¬', 'ìˆœì²œ', 'ì—¬ìˆ˜',
            # ê´‘ì£¼
            'ê´‘ì£¼',
            # ê²½ë¶
            'ê²½ì‚°', 'ê²½ì£¼', 'êµ¬ë¯¸', 'ê¹€ì²œ', 'ë¬¸ê²½', 'ìƒì£¼', 'ì•ˆë™', 'ì˜ì£¼',
            'ì˜ì²œ', 'í¬í•­',
            # ê²½ë‚¨
            'ê±°ì œ', 'ê¹€í•´', 'ë°€ì–‘', 'ì‚¬ì²œ', 'ì–‘ì‚°', 'ì§„ì£¼', 'ì°½ì›', 'í†µì˜',
            # ëŒ€êµ¬
            'ëŒ€êµ¬',
            # ë¶€ì‚°
            'ë¶€ì‚°',
            # ìš¸ì‚°
            'ìš¸ì‚°',
            # ì œì£¼
            'ì œì£¼'
        ]

    def setup(self):
        print('ë¸Œë¼ìš°ì € ì„¤ì •...')
        opts = Options()
        opts.add_argument('--no-sandbox')
        opts.add_argument('--disable-dev-shm-usage')
        opts.add_argument('--disable-blink-features=AutomationControlled')
        opts.add_argument('--headless')
        opts.add_argument('--window-size=1920,1080')
        opts.add_experimental_option("excludeSwitches", ["enable-automation"])
        opts.add_experimental_option('useAutomationExtension', False)
        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=opts)
        print('ì¤€ë¹„ ì™„ë£Œ')

    def login(self):
        print('ë¡œê·¸ì¸...')
        self.driver.get('https://dkxm8.com/bbs/login.php')
        time.sleep(2)
        self.driver.find_element(By.NAME, 'mb_id').send_keys(USERNAME)
        self.driver.find_element(By.NAME, 'mb_password').send_keys(PASSWORD)
        self.driver.find_element(By.CSS_SELECTOR, 'input[type=submit]').click()
        time.sleep(3)
        print('ë¡œê·¸ì¸ ì™„ë£Œ\n')

    def crawl_area(self, area_name):
        """íŠ¹ì • ì§€ì—­ì˜ ëª¨ë“  ì—…ì†Œ í¬ë¡¤ë§"""
        try:
            url = f"https://dkxm8.com/?area={area_name}"
            self.driver.get(url)
            time.sleep(3)

            # ì—…ì²´ ì¹´ë“œ ì°¾ê¸°
            cards = []
            selectors = ["div.gal_top", "div.gal_list", "div[class*='gal']"]

            for selector in selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if len(elements) > 0:
                        cards = elements
                        break
                except:
                    continue

            if not cards:
                return []

            items = []
            for idx, card in enumerate(cards, 1):
                try:
                    # ì—…ì²´ëª…
                    title = ""
                    try:
                        h4 = card.find_element(By.TAG_NAME, "h4")
                        title = h4.text.strip()
                    except:
                        pass

                    # URL
                    shop_url = ""
                    try:
                        profile_link = card.find_element(By.CSS_SELECTOR, "a[href*='profile_popup']")
                        shop_url = profile_link.get_attribute('href')
                    except:
                        pass

                    # ì„¤ëª…
                    description = ""
                    try:
                        strong = card.find_element(By.CSS_SELECTOR, ".galInfo strong")
                        description = strong.text.strip()
                    except:
                        pass

                    # ì˜ì—…ì‹œê°„
                    hours = ""
                    try:
                        hour_elem = card.find_element(By.XPATH, ".//p[b[text()='ì˜ì—…ì‹œê°„']]/span")
                        hours = hour_elem.text.strip()
                    except:
                        pass

                    # ì „í™”ë²ˆí˜¸
                    phone = ""
                    try:
                        phone_elem = card.find_element(By.XPATH, ".//p[b[text()='ì „í™”ë²ˆí˜¸']]/span")
                        phone = phone_elem.text.strip()
                    except:
                        pass

                    # ì¹´ì¹´ì˜¤í†¡
                    kakao_id = ""
                    try:
                        kakao_elem = card.find_element(By.XPATH, ".//p[b[contains(text(),'ì¹´í†¡')]]/span")
                        kakao_id = kakao_elem.text.strip()
                    except:
                        pass

                    # í…”ë ˆê·¸ë¨
                    telegram_id = ""
                    try:
                        telegram_elem = card.find_element(By.XPATH, ".//p[b[contains(text(),'í…”ë ˆ')]]/span")
                        telegram_id = telegram_elem.text.strip()
                    except:
                        pass

                    # ì¸ë„¤ì¼
                    thumbnail = ""
                    try:
                        img = card.find_element(By.CSS_SELECTOR, ".imgwrap img")
                        thumbnail = img.get_attribute('src')
                        if thumbnail and not thumbnail.startswith('http'):
                            thumbnail = 'https://dkxm8.com' + thumbnail
                        if not thumbnail:
                            thumbnail = 'https://dkxm8.com/img/temp_thum.jpg'
                    except:
                        thumbnail = 'https://dkxm8.com/img/temp_thum.jpg'

                    if title or shop_url:
                        item = {
                            'title': title,
                            'url': shop_url,
                            'description': description,
                            'hours': hours,
                            'phone': phone,
                            'kakao_id': kakao_id,
                            'telegram_id': telegram_id,
                            'thumbnail': thumbnail
                        }
                        items.append(item)

                except Exception as e:
                    continue

            return items

        except Exception as e:
            print(f'  âœ— ì˜¤ë¥˜: {e}')
            return []

    def run(self):
        print('='*60)
        print('ì „êµ­ ëª¨ë“  ì§€ì—­ ìˆœì°¨ í¬ë¡¤ë§')
        print('='*60)

        self.setup()
        self.login()

        total_areas = len(self.areas)

        for idx, area in enumerate(self.areas, 1):
            print(f'[{idx}/{total_areas}] {area} í¬ë¡¤ë§ ì¤‘...', end=' ')

            items = self.crawl_area(area)

            if items:
                self.results.extend(items)
                print(f'âœ“ {len(items)}ê°œ ìˆ˜ì§‘')
            else:
                print('â—‹ ì—…ì†Œ ì—†ìŒ')

            # 10ê°œ ì§€ì—­ë§ˆë‹¤ ì¤‘ê°„ ì €ì¥
            if idx % 10 == 0:
                temp_file = f'all_areas_temp_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
                with open(temp_file, 'w', encoding='utf-8') as f:
                    json.dump(self.results, f, ensure_ascii=False, indent=2)
                print(f'  â†’ ì¤‘ê°„ ì €ì¥: {temp_file} (ëˆ„ì  {len(self.results)}ê°œ)\n')

            time.sleep(2)

        # ìµœì¢… ì €ì¥
        output = f'all_areas_complete_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(output, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)

        print(f'\n{"="*60}')
        print(f'âœ… ì™„ë£Œ: {len(self.results)}ê°œ ì—…ì†Œ â†’ {output}')
        print(f'{"="*60}')

        # í†µê³„
        real_thumbs = len([x for x in self.results if x.get('thumbnail', '').startswith('https://dkxm8.com/data/file/main')])
        print(f'\nğŸ“Š í†µê³„:')
        print(f'  ì´ ì—…ì†Œ: {len(self.results)}ê°œ')
        print(f'  ì‹¤ì œ ì¸ë„¤ì¼: {real_thumbs}ê°œ ({real_thumbs/len(self.results)*100:.1f}%)')

        self.driver.quit()

if __name__ == '__main__':
    crawler = AllAreasCrawler()
    crawler.run()
