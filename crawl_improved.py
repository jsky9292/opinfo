#!/usr/bin/env python3
"""
dkxm8.com ê°œì„ ëœ í¬ë¡¤ëŸ¬ - ëª¨ë“  ì—…ì²´ ìˆ˜ì§‘
"""

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
from datetime import datetime

# ë¡œê·¸ì¸ ì •ë³´
USERNAME = "mix1220"
PASSWORD = "1234"

# í…ŒìŠ¤íŠ¸í•  ì§€ì—­ë“¤ (ëŒ€ì „ë§Œ ìš°ì„  í…ŒìŠ¤íŠ¸)
TEST_AREAS = ["ëŒ€ì „"]

class ImprovedCrawler:
    def __init__(self, headless=False):
        self.headless = headless
        self.driver = None
        self.results = []

    def setup_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì„¤ì •"""
        print("ğŸ”§ ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ì„¤ì • ì¤‘...")

        chrome_options = Options()

        if self.headless:
            chrome_options.add_argument('--headless=new')

        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.driver.implicitly_wait(10)

        print("âœ… ë¸Œë¼ìš°ì € ì¤€ë¹„ ì™„ë£Œ\n")

    def login(self):
        """ë¡œê·¸ì¸"""
        try:
            print("ğŸ”‘ ë¡œê·¸ì¸ ì¤‘...")
            self.driver.get("https://dkxm8.com/bbs/login.php")
            time.sleep(3)

            username_field = self.driver.find_element(By.NAME, "mb_id")
            password_field = self.driver.find_element(By.NAME, "mb_password")

            username_field.clear()
            username_field.send_keys(USERNAME)

            password_field.clear()
            password_field.send_keys(PASSWORD)

            submit_btn = self.driver.find_element(By.CSS_SELECTOR, "input[type='submit']")
            submit_btn.click()

            time.sleep(5)

            if 'login.php' in self.driver.current_url:
                print("âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨")
                return False

            print("âœ… ë¡œê·¸ì¸ ì„±ê³µ!\n")
            return True

        except Exception as e:
            print(f"âŒ ë¡œê·¸ì¸ ì˜¤ë¥˜: {e}")
            return False

    def scroll_to_load_all(self):
        """í˜ì´ì§€ ìŠ¤í¬ë¡¤í•´ì„œ ëª¨ë“  ì»¨í…ì¸  ë¡œë“œ"""
        last_height = self.driver.execute_script("return document.body.scrollHeight")

        for i in range(5):  # ìµœëŒ€ 5ë²ˆ ìŠ¤í¬ë¡¤
            # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)

            # ìƒˆ ë†’ì´ í™•ì¸
            new_height = self.driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height

    def find_all_shop_cards(self):
        """ëª¨ë“  ì—…ì²´ ì¹´ë“œ ì°¾ê¸° - ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„"""
        all_cards = []

        # ì‹œë„í•  ì…€ë ‰í„° ë¦¬ìŠ¤íŠ¸
        selectors = [
            "div.gal_top",           # ì¶”ì²œ ì—…ì²´
            "div.gal_list",          # ì¼ë°˜ ì—…ì²´ ë¦¬ìŠ¤íŠ¸
            "div[class*='gal']",     # galë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  div
            "div.shop-card",         # ì—…ì²´ ì¹´ë“œ
            "div.shop-item",         # ì—…ì²´ ì•„ì´í…œ
            "article",               # article íƒœê·¸
            "div[onclick*='profile']", # í”„ë¡œí•„ í´ë¦­ ì´ë²¤íŠ¸ ìˆëŠ” div
        ]

        for selector in selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if elements:
                    print(f"   âœ“ '{selector}' ë°œê²¬: {len(elements)}ê°œ")
                    all_cards.extend(elements)
            except Exception as e:
                continue

        # ì¤‘ë³µ ì œê±° (ê°™ì€ ìš”ì†Œê°€ ì—¬ëŸ¬ ì…€ë ‰í„°ì— ê±¸ë¦´ ìˆ˜ ìˆìŒ)
        unique_cards = list(set(all_cards))
        return unique_cards

    def extract_shop_info(self, card):
        """ì¹´ë“œì—ì„œ ì—…ì²´ ì •ë³´ ì¶”ì¶œ"""
        info = {}

        try:
            # ì—…ì²´ëª… ì¶”ì¶œ - ì—¬ëŸ¬ ë°©ë²• ì‹œë„
            title = ""
            try:
                h4 = card.find_element(By.TAG_NAME, "h4")
                title = h4.text.strip()
            except:
                try:
                    h3 = card.find_element(By.TAG_NAME, "h3")
                    title = h3.text.strip()
                except:
                    try:
                        title_elem = card.find_element(By.CSS_SELECTOR, ".shop-title, .title, .name")
                        title = title_elem.text.strip()
                    except:
                        pass

            if not title:
                return None

            info['title'] = title

            # í”„ë¡œí•„ URL
            try:
                profile_link = card.find_element(By.CSS_SELECTOR, "a[href*='profile']")
                info['profile_url'] = profile_link.get_attribute('href')
            except:
                info['profile_url'] = ""

            # ì„¤ëª…
            try:
                desc_elem = card.find_element(By.CSS_SELECTOR, ".galInfo strong, .description, .desc")
                info['description'] = desc_elem.text.strip()
            except:
                info['description'] = ""

            # ì˜ì—…ì‹œê°„
            try:
                hours_elem = card.find_element(By.XPATH, ".//p[contains(., 'ì˜ì—…ì‹œê°„')]//span | .//span[contains(@class, 'hours')]")
                info['hours'] = hours_elem.text.strip()
            except:
                info['hours'] = ""

            # ì´ë¯¸ì§€
            try:
                img = card.find_element(By.TAG_NAME, "img")
                info['image'] = img.get_attribute('src')
            except:
                info['image'] = ""

            # ì¹´ì¹´ì˜¤í†¡ ID
            try:
                kakao_elem = card.find_element(By.XPATH, ".//a[contains(@href, 'kakao') or contains(., 'ì¹´í†¡')]")
                info['kakao_id'] = kakao_elem.text.strip()
            except:
                info['kakao_id'] = ""

            # í…”ë ˆê·¸ë¨ ID
            try:
                tg_elem = card.find_element(By.XPATH, ".//a[contains(@href, 'telegram') or contains(., 'í…”ë ˆ')]")
                info['telegram_id'] = tg_elem.text.strip()
            except:
                info['telegram_id'] = ""

            return info

        except Exception as e:
            print(f"      âš ï¸ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def crawl_area(self, area_name):
        """íŠ¹ì • ì§€ì—­ í¬ë¡¤ë§"""
        print(f"\nğŸ“ {area_name} í¬ë¡¤ë§ ì‹œì‘...")

        items = []

        try:
            url = f"https://dkxm8.com/?area={area_name}"
            self.driver.get(url)
            print(f"   âœ“ í˜ì´ì§€ ë¡œë“œ: {url}")
            time.sleep(3)

            # í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¡¤
            print(f"   â¬ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
            self.scroll_to_load_all()

            # ëª¨ë“  ì—…ì²´ ì¹´ë“œ ì°¾ê¸°
            print(f"   ğŸ” ì—…ì²´ ì¹´ë“œ ê²€ìƒ‰ ì¤‘...")
            cards = self.find_all_shop_cards()

            if not cards:
                print(f"   âš ï¸ ì—…ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return items

            print(f"   âœ“ ì´ {len(cards)}ê°œ ì¹´ë“œ ë°œê²¬")

            # ê° ì¹´ë“œì—ì„œ ì •ë³´ ì¶”ì¶œ
            print(f"   ğŸ“ ì •ë³´ ì¶”ì¶œ ì¤‘...")
            for idx, card in enumerate(cards, 1):
                info = self.extract_shop_info(card)
                if info and info.get('title'):
                    info['area'] = area_name
                    info['crawled_at'] = datetime.now().isoformat()
                    items.append(info)
                    print(f"      [{idx}/{len(cards)}] âœ“ {info['title']}")

            print(f"   âœ… {area_name}: {len(items)}ê°œ ì—…ì²´ ìˆ˜ì§‘ ì™„ë£Œ")

        except Exception as e:
            print(f"   âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

        return items

    def run(self):
        """í¬ë¡¤ëŸ¬ ì‹¤í–‰"""
        try:
            self.setup_driver()

            if not self.login():
                return

            print("\n" + "="*70)
            print("ğŸš€ ê°œì„ ëœ í¬ë¡¤ëŸ¬ ì‹œì‘ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)")
            print("="*70)

            all_results = []

            for area in TEST_AREAS:
                items = self.crawl_area(area)
                all_results.extend(items)
                time.sleep(2)

            # ê²°ê³¼ ì €ì¥
            if all_results:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"improved_crawl_{timestamp}.json"

                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(all_results, f, ensure_ascii=False, indent=2)

                print("\n" + "="*70)
                print(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(all_results)}ê°œ ì—…ì²´ ìˆ˜ì§‘")
                print(f"ğŸ’¾ íŒŒì¼ ì €ì¥: {filename}")
                print("="*70)
            else:
                print("\nâš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

        finally:
            if self.driver:
                print("\nğŸ”š ë¸Œë¼ìš°ì € ì¢…ë£Œ")
                self.driver.quit()

if __name__ == "__main__":
    print("â„¹ï¸  ê°œì„ ëœ í¬ë¡¤ëŸ¬ - ëŒ€ì „ ì§€ì—­ í…ŒìŠ¤íŠ¸")
    crawler = ImprovedCrawler(headless=False)  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ OFF
    crawler.run()
